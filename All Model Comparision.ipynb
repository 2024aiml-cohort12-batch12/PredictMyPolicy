{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7iu8dI_eXIq",
    "outputId": "6aec38eb-11d0-4736-d5af-c8bd92172311"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install imbalanced-learn xgboost --quiet\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.combine import SMOTEENN\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "TARGET_COL = \"renewal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (79853, 13)\n",
      "Target column 'renewal' found: True\n",
      "Categorical columns (2): ['sourcing_channel', 'residence_area_type']\n",
      "Numerical columns (10): ['id', 'perc_premium_paid_by_cash_credit', 'age_in_days', 'Income', 'Count_3-6_months_late', 'Count_6-12_months_late', 'Count_more_than_12_months_late', 'application_underwriting_score', 'no_of_premiums_paid', 'premium']\n",
      "Class distribution: Counter({1: 74855, 0: 4998})\n"
     ]
    }
   ],
   "source": [
    "# Data Import - Choose one option below\n",
    "\n",
    "# Option 1: Google Colab with Drive (uncomment to use)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# TRAIN_CSV_PATH = \"/content/drive/MyDrive/Capstone Project/train_ZoGVYWq.csv\"\n",
    "\n",
    "# Option 2: Local file path (uncomment to use)\n",
    "TRAIN_CSV_PATH = \"train_ZoGVYWq.csv\"  # Update with your local file path\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Target column '{TARGET_COL}' found: {TARGET_COL in df.columns}\")\n",
    "\n",
    "# Separate features and target\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL]).copy()\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_idx = [X.columns.get_loc(c) for c in cat_cols]  # for SMOTENC\n",
    "\n",
    "print(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")\n",
    "print(f\"Numerical columns ({len(num_cols)}): {num_cols}\")\n",
    "print(f\"Class distribution: {Counter(y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (63882, 12)\n",
      "Validation set shape: (15971, 12)\n",
      "Training class distribution: Counter({1: 59884, 0: 3998})\n",
      "Validation class distribution: Counter({1: 14971, 0: 1000})\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation Split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_valid.shape}\")\n",
    "print(f\"Training class distribution: {Counter(y_train)}\")\n",
    "print(f\"Validation class distribution: {Counter(y_valid)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "Training set: 0\n",
      "Validation set: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing - Handle Missing Values\n",
    "\n",
    "# Impute NaNs (NO OHE)\n",
    "# Numeric: median (fit on train), Categorical: most frequent (fit on train)\n",
    "num_medians = X_train[num_cols].median()\n",
    "X_train[num_cols] = X_train[num_cols].fillna(num_medians)\n",
    "X_valid[num_cols] = X_valid[num_cols].fillna(num_medians)\n",
    "\n",
    "cat_modes = {c: X_train[c].mode(dropna=True)[0] for c in cat_cols}\n",
    "X_train[cat_cols] = X_train[cat_cols].fillna(pd.Series(cat_modes))\n",
    "X_valid[cat_cols] = X_valid[cat_cols].fillna(pd.Series(cat_modes))\n",
    "\n",
    "# Ensure category dtype (needed for clean round-trip)\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "    # lock validation to same category set (unknown -> make category; fallback to string then category)\n",
    "    X_valid[c] = pd.Categorical(X_valid[c].astype(str), categories=X_train[c].cat.categories)\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(f\"Training set: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Validation set: {X_valid.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution BEFORE resampling: Counter({1: 59884, 0: 3998})\n"
     ]
    }
   ],
   "source": [
    "# Encoding Functions for Resampling\n",
    "\n",
    "def to_encoded_array(df_cat_num, cat_columns):\n",
    "    \"\"\"Convert DataFrame to encoded array for SMOTE resampling\"\"\"\n",
    "    arr = df_cat_num.copy()\n",
    "    # integer codes for categoricals; continuous stay numeric\n",
    "    for c in cat_columns:\n",
    "        # use existing 'category' codes; unseen become -1 -> fix to 0 by adding a 'UNK' if needed\n",
    "        codes = arr[c].cat.codes.values\n",
    "        # if -1 exists (unknown), add an extra code\n",
    "        if (codes == -1).any():\n",
    "            # extend categories\n",
    "            new_cats = list(arr[c].cat.categories) + [\"__UNK__\"]\n",
    "            arr[c] = pd.Categorical(arr[c].astype(str), categories=new_cats)\n",
    "            codes = arr[c].cat.codes.values\n",
    "        arr[c] = codes.astype(np.int64)\n",
    "    return arr.values\n",
    "\n",
    "def from_encoded_array(arr, ref_df, cat_columns):\n",
    "    \"\"\"Convert encoded array back to DataFrame with correct dtypes\"\"\"\n",
    "    # rebuild DataFrame with original column names\n",
    "    out = pd.DataFrame(arr, columns=ref_df.columns)\n",
    "    # cast dtypes back: numeric as float, categoricals as pandas 'category' using original categories if possible\n",
    "    for c in num_cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    for c in cat_columns:\n",
    "        # original categories (plus optional UNK if we added earlier)\n",
    "        ref_cats = list(ref_df[c].cat.categories)\n",
    "        # if any code >= len(ref_cats), add UNK\n",
    "        max_code = int(out[c].max())\n",
    "        if max_code >= len(ref_cats):\n",
    "            ref_cats = ref_cats + [\"__UNK__\"]\n",
    "        out[c] = pd.Categorical.from_codes(out[c].astype(int), categories=ref_cats)\n",
    "    return out\n",
    "\n",
    "# Prepare encoded arrays for resampling\n",
    "Xtr_enc = to_encoded_array(X_train, cat_cols)\n",
    "Xva_for_model = X_valid.copy()  # model expects category dtype, already set\n",
    "\n",
    "print(\"Train class distribution BEFORE resampling:\", Counter(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling methods configured:\n",
      "- SMOTENC 1:1\n",
      "- SMOTEENN (SMOTENC+ENN)\n"
     ]
    }
   ],
   "source": [
    "# Resampling Methods Configuration\n",
    "\n",
    "# Define resampling methods\n",
    "resamplers = [\n",
    "    (\"SMOTENC 1:1\", SMOTENC(categorical_features=cat_idx, sampling_strategy=\"auto\",\n",
    "                            k_neighbors=5, random_state=RANDOM_STATE)),\n",
    "    (\"SMOTEENN (SMOTENC+ENN)\", SMOTEENN(\n",
    "        smote=SMOTENC(categorical_features=cat_idx, sampling_strategy=\"auto\",\n",
    "                      k_neighbors=5, random_state=RANDOM_STATE),\n",
    "        random_state=RANDOM_STATE\n",
    "    )),\n",
    "]\n",
    "\n",
    "# Initialize storage for results\n",
    "summary = []\n",
    "conf_mats = {}\n",
    "\n",
    "print(\"Resampling methods configured:\")\n",
    "for name, _ in resamplers:\n",
    "    print(f\"- {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SMOTENC 1:1 ===\n",
      "AFTER resample: Counter({np.int64(1): 59884, np.int64(0): 59884})\n",
      "\n",
      "=== SMOTEENN (SMOTENC+ENN) ===\n",
      "AFTER resample: Counter({np.int64(0): 52200, np.int64(1): 39607})\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "for name, resampler in resamplers:\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Resample on encoded arrays (handles NaNs already)\n",
    "    X_res_arr, y_res = resampler.fit_resample(Xtr_enc, y_train.values)\n",
    "    print(\"AFTER resample:\", Counter(y_res))\n",
    "\n",
    "    # Convert back to DataFrame with correct dtypes for model (categoricals as 'category')\n",
    "    X_res = from_encoded_array(X_res_arr, X_train, cat_cols)\n",
    "\n",
    "    # XGBoost with native categorical handling (no OHE)\n",
    "    clf = XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        tree_method=\"approx\",\n",
    "        enable_categorical=True,\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0\n",
    "    )\n",
    "    clf.fit(X_res, y_res)\n",
    "\n",
    "    # Evaluate\n",
    "    y_prob = clf.predict_proba(Xva_for_model)  # Get probabilities for all classes\n",
    "    y_pred = (y_prob[:, 1] >= 0.51).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    prec = precision_score(y_valid, y_pred, zero_division=0, average=None)  # Per-class precision\n",
    "    rec = recall_score(y_valid, y_pred, zero_division=0, average=None)      # Per-class recall\n",
    "    f1 = f1_score(y_valid, y_pred, zero_division=0, average=None)           # Per-class F1\n",
    "    \n",
    "    # Per-class ROC_AUC\n",
    "    roc_class_0 = roc_auc_score(1 - y_valid, y_prob[:, 0])\n",
    "    roc_class_1 = roc_auc_score(y_valid, y_prob[:, 1])\n",
    "    roc = [roc_class_0, roc_class_1]\n",
    "\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    conf_mats[name] = cm\n",
    "    summary.append({\n",
    "        \"Method\": name,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision (Class 0)\": round(prec[0], 4),\n",
    "        \"Precision (Class 1)\": round(prec[1], 4),\n",
    "        \"Recall (Class 0)\": round(rec[0], 4),\n",
    "        \"Recall (Class 1)\": round(rec[1], 4),\n",
    "        \"F1 (Class 0)\": round(f1[0], 4),\n",
    "        \"F1 (Class 1)\": round(f1[1], 4),\n",
    "        \"ROC_AUC (Class 0)\": round(roc[0], 4),\n",
    "        \"ROC_AUC (Class 1)\": round(roc[1], 4)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary (including per-class metrics) =====\n",
      "                   Method  Accuracy  Precision (Class 0)  Precision (Class 1)  \\\n",
      "0             SMOTENC 1:1    0.9371               0.4916               0.9456   \n",
      "1  SMOTEENN (SMOTENC+ENN)    0.9302               0.4050               0.9508   \n",
      "\n",
      "   Recall (Class 0)  Recall (Class 1)  F1 (Class 0)  F1 (Class 1)  \\\n",
      "0             0.147            0.9898        0.2263        0.9672   \n",
      "1             0.243            0.9762        0.3038        0.9633   \n",
      "\n",
      "   ROC_AUC (Class 0)  ROC_AUC (Class 1)  \n",
      "0             0.8406             0.8406  \n",
      "1             0.8302             0.8302  \n",
      "\n",
      "===== Confusion Matrices (rows=true, cols=pred) =====\n",
      "\n",
      "SMOTENC 1:1\n",
      "[[  147   853]\n",
      " [  152 14819]]\n",
      "\n",
      "SMOTEENN (SMOTENC+ENN)\n",
      "[[  243   757]\n",
      " [  357 14614]]\n"
     ]
    }
   ],
   "source": [
    "# Results Summary\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "print(\"\\n===== Summary (including per-class metrics) =====\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\n===== Confusion Matrices (rows=true, cols=pred) =====\")\n",
    "for k, v in conf_mats.items():\n",
    "    print(f\"\\n{k}\\n{v}\")\n",
    "\n",
    "# Optional: Save results to CSV\n",
    "# summary_df.to_csv('smote_results.csv', index=False)\n",
    "# print(\"\\nResults saved to 'smote_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 14 classifiers loaded with default parameters\n",
      "Available classifiers:\n",
      "  - Random Forest\n",
      "  - Gradient Boosting\n",
      "  - AdaBoost\n",
      "  - Logistic Regression\n",
      "  - Ridge Classifier\n",
      "  - SVM\n",
      "  - Decision Tree\n",
      "  - K-Nearest Neighbors\n",
      "  - Naive Bayes\n",
      "  - Linear Discriminant\n",
      "  - Quadratic Discriminant\n",
      "  - SGD Classifier\n",
      "  - Extra Trees\n",
      "  - XGBoost\n"
     ]
    }
   ],
   "source": [
    "# All Available Classifiers with Default Parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# All classifiers with default parameters\n",
    "ALL_CLASSIFIERS = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Ridge Classifier': RidgeClassifier(random_state=RANDOM_STATE),\n",
    "    'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Linear Discriminant': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant': QuadraticDiscriminantAnalysis(),\n",
    "    'SGD Classifier': SGDClassifier(random_state=RANDOM_STATE),\n",
    "    'Extra Trees': ExtraTreesClassifier(random_state=RANDOM_STATE),\n",
    "    'XGBoost': XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss', enable_categorical=True)\n",
    "}\n",
    "\n",
    "print(f\"✅ {len(ALL_CLASSIFIERS)} classifiers loaded with default parameters\")\n",
    "print(\"Available classifiers:\")\n",
    "for name in ALL_CLASSIFIERS.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model comparison function ready!\n",
      "\n",
      "Usage: results = compare_models(X_train, X_test, y_train, y_test, ALL_CLASSIFIERS)\n",
      "Or use a subset: results = compare_models(X_train, X_test, y_train, y_test, {'Random Forest': RandomForestClassifier(), 'XGBoost': XGBClassifier()})\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison Function\n",
    "\n",
    "def compare_models(X_train, X_test, y_train, y_test, models_dict):\n",
    "    \"\"\"\n",
    "    Compare multiple classification models and print results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, X_test : DataFrame\n",
    "        Training and testing features\n",
    "    y_train, y_test : Series\n",
    "        Training and testing target variables\n",
    "    models_dict : dict\n",
    "        Dictionary with model names as keys and model instances as values\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import time\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MODEL COMPARISON RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Prepare data for models that don't handle categorical features natively\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "    \n",
    "    # Encode categorical variables for non-XGBoost models\n",
    "    label_encoders = {}\n",
    "    for col in cat_cols:\n",
    "        if col in X_train_encoded.columns:\n",
    "            le = LabelEncoder()\n",
    "            # Fit on training data and transform both train and test\n",
    "            X_train_encoded[col] = le.fit_transform(X_train_encoded[col].astype(str))\n",
    "            X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"\\n🔄 Training {model_name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Use original data for XGBoost (handles categorical natively with enable_categorical=True)\n",
    "            if 'XGBoost' in model_name:\n",
    "                # Ensure categorical columns are properly formatted for XGBoost\n",
    "                X_train_xgb = X_train.copy()\n",
    "                X_test_xgb = X_test.copy()\n",
    "                \n",
    "                # Convert categorical columns to category type for XGBoost\n",
    "                for col in cat_cols:\n",
    "                    if col in X_train_xgb.columns:\n",
    "                        X_train_xgb[col] = X_train_xgb[col].astype('category')\n",
    "                        X_test_xgb[col] = X_test_xgb[col].astype('category')\n",
    "                \n",
    "                model.fit(X_train_xgb, y_train)\n",
    "                y_pred = model.predict(X_test_xgb)\n",
    "                y_pred_proba = model.predict_proba(X_test_xgb)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            else:\n",
    "                # Use encoded data for other models\n",
    "                model.fit(X_train_encoded, y_train)\n",
    "                y_pred = model.predict(X_test_encoded)\n",
    "                y_pred_proba = model.predict_proba(X_test_encoded)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Calculate metrics - per class and overall\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Per-class metrics\n",
    "            precision_per_class = precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "            recall_per_class = recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "            f1_per_class = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
    "            \n",
    "            # Overall weighted metrics\n",
    "            precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            \n",
    "            # ROC AUC (only if model supports probability prediction)\n",
    "            roc_auc = None\n",
    "            if y_pred_proba is not None:\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "                except:\n",
    "                    roc_auc = None\n",
    "            \n",
    "            # Store results with per-class metrics\n",
    "            result = {\n",
    "                'Model': model_name,\n",
    "                'Accuracy': round(accuracy, 4),\n",
    "                'Precision (Class 0)': round(precision_per_class[0], 4),\n",
    "                'Precision (Class 1)': round(precision_per_class[1], 4),\n",
    "                'Precision (Weighted)': round(precision_weighted, 4),\n",
    "                'Recall (Class 0)': round(recall_per_class[0], 4),\n",
    "                'Recall (Class 1)': round(recall_per_class[1], 4),\n",
    "                'Recall (Weighted)': round(recall_weighted, 4),\n",
    "                'F1-Score (Class 0)': round(f1_per_class[0], 4),\n",
    "                'F1-Score (Class 1)': round(f1_per_class[1], 4),\n",
    "                'F1-Score (Weighted)': round(f1_weighted, 4),\n",
    "                'ROC-AUC': round(roc_auc, 4) if roc_auc else 'N/A',\n",
    "                'Training Time (s)': round(training_time, 4)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            # Print individual results\n",
    "            print(f\"   ✅ {model_name} completed in {training_time:.2f}s\")\n",
    "            print(f\"   📊 Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"   📈 F1-Score - Class 0: {f1_per_class[0]:.4f}, Class 1: {f1_per_class[1]:.4f}, Weighted: {f1_weighted:.4f}\")\n",
    "            print(f\"   🎯 Precision - Class 0: {precision_per_class[0]:.4f}, Class 1: {precision_per_class[1]:.4f}\")\n",
    "            print(f\"   🔍 Recall - Class 0: {recall_per_class[0]:.4f}, Class 1: {recall_per_class[1]:.4f}\")\n",
    "            if roc_auc:\n",
    "                print(f\"   📈 ROC-AUC: {roc_auc:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error training {model_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by F1-Score (Weighted) (descending)\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values('F1-Score (Weighted)', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "        print(\"📊 COMPARISON SUMMARY - PER CLASS METRICS\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # Display key metrics in a readable format\n",
    "        display_cols = ['Model', 'Accuracy', 'Precision (Class 0)', 'Precision (Class 1)', \n",
    "                       'Recall (Class 0)', 'Recall (Class 1)', 'F1-Score (Class 0)', \n",
    "                       'F1-Score (Class 1)', 'F1-Score (Weighted)', 'ROC-AUC', 'Training Time (s)']\n",
    "        print(results_df[display_cols].to_string(index=False))\n",
    "        \n",
    "        # Best model\n",
    "        best_model = results_df.iloc[0]\n",
    "        print(f\"\\n🏆 BEST MODEL: {best_model['Model']}\")\n",
    "        print(f\"   Accuracy: {best_model['Accuracy']}\")\n",
    "        print(f\"   F1-Score (Class 0 - No Renewal): {best_model['F1-Score (Class 0)']}\")\n",
    "        print(f\"   F1-Score (Class 1 - Renewal): {best_model['F1-Score (Class 1)']}\")\n",
    "        print(f\"   F1-Score (Weighted): {best_model['F1-Score (Weighted)']}\")\n",
    "        if best_model['ROC-AUC'] != 'N/A':\n",
    "            print(f\"   ROC-AUC: {best_model['ROC-AUC']}\")\n",
    "        \n",
    "        # Additional insights\n",
    "        print(f\"\\n📋 CLASS INTERPRETATION:\")\n",
    "        print(f\"   Class 0: No Renewal (Minority class)\")\n",
    "        print(f\"   Class 1: Renewal (Majority class)\")\n",
    "        print(f\"   Focus on Class 0 metrics for detecting non-renewals!\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"✅ Model comparison function ready!\")\n",
    "print(\"\\nUsage: results = compare_models(X_train, X_test, y_train, y_test, ALL_CLASSIFIERS)\")\n",
    "print(\"Or use a subset: results = compare_models(X_train, X_test, y_train, y_test, {'Random Forest': RandomForestClassifier(), 'XGBoost': XGBClassifier()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "🔄 Training Random Forest...\n",
      "   ✅ Random Forest completed in 12.41s\n",
      "   📊 Accuracy: 0.9376\n",
      "   📈 F1-Score - Class 0: 0.1821, Class 1: 0.9675, Weighted: 0.9184\n",
      "   🎯 Precision - Class 0: 0.5068, Class 1: 0.9436\n",
      "   🔍 Recall - Class 0: 0.1110, Class 1: 0.9928\n",
      "   📈 ROC-AUC: 0.8260\n",
      "\n",
      "🔄 Training Gradient Boosting...\n",
      "   ✅ Gradient Boosting completed in 12.50s\n",
      "   📊 Accuracy: 0.9376\n",
      "   📈 F1-Score - Class 0: 0.1994, Class 1: 0.9676, Weighted: 0.9195\n",
      "   🎯 Precision - Class 0: 0.5082, Class 1: 0.9443\n",
      "   🔍 Recall - Class 0: 0.1240, Class 1: 0.9920\n",
      "   📈 ROC-AUC: 0.8452\n",
      "\n",
      "🔄 Training AdaBoost...\n",
      "   ✅ AdaBoost completed in 4.21s\n",
      "   📊 Accuracy: 0.9381\n",
      "   📈 F1-Score - Class 0: 0.1821, Class 1: 0.9679, Weighted: 0.9187\n",
      "   🎯 Precision - Class 0: 0.5288, Class 1: 0.9435\n",
      "   🔍 Recall - Class 0: 0.1100, Class 1: 0.9935\n",
      "   📈 ROC-AUC: 0.8352\n",
      "\n",
      "🔄 Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YaswanthreddyDasari\\Downloads\\hr-policy-assistant-bot\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Logistic Regression completed in 3.88s\n",
      "   📊 Accuracy: 0.9383\n",
      "   📈 F1-Score - Class 0: 0.2010, Class 1: 0.9679, Weighted: 0.9199\n",
      "   🎯 Precision - Class 0: 0.5299, Class 1: 0.9443\n",
      "   🔍 Recall - Class 0: 0.1240, Class 1: 0.9927\n",
      "   📈 ROC-AUC: 0.8322\n",
      "\n",
      "🔄 Training Ridge Classifier...\n",
      "   ✅ Ridge Classifier completed in 0.03s\n",
      "   📊 Accuracy: 0.9384\n",
      "   📈 F1-Score - Class 0: 0.1183, Class 1: 0.9681, Weighted: 0.9149\n",
      "   🎯 Precision - Class 0: 0.5690, Class 1: 0.9411\n",
      "   🔍 Recall - Class 0: 0.0660, Class 1: 0.9967\n",
      "\n",
      "🔄 Training SVM...\n",
      "   ✅ SVM completed in 247.51s\n",
      "   📊 Accuracy: 0.9374\n",
      "   📈 F1-Score - Class 0: 0.0000, Class 1: 0.9677, Weighted: 0.9071\n",
      "   🎯 Precision - Class 0: 0.0000, Class 1: 0.9374\n",
      "   🔍 Recall - Class 0: 0.0000, Class 1: 1.0000\n",
      "   📈 ROC-AUC: 0.5066\n",
      "\n",
      "🔄 Training Decision Tree...\n",
      "   ✅ Decision Tree completed in 0.67s\n",
      "   📊 Accuracy: 0.8937\n",
      "   📈 F1-Score - Class 0: 0.2205, Class 1: 0.9430, Weighted: 0.8977\n",
      "   🎯 Precision - Class 0: 0.2039, Class 1: 0.9486\n",
      "   🔍 Recall - Class 0: 0.2400, Class 1: 0.9374\n",
      "   📈 ROC-AUC: 0.5887\n",
      "\n",
      "🔄 Training K-Nearest Neighbors...\n",
      "   ✅ K-Nearest Neighbors completed in 0.80s\n",
      "   📊 Accuracy: 0.9346\n",
      "   📈 F1-Score - Class 0: 0.0076, Class 1: 0.9662, Weighted: 0.9061\n",
      "   🎯 Precision - Class 0: 0.0755, Class 1: 0.9374\n",
      "   🔍 Recall - Class 0: 0.0040, Class 1: 0.9967\n",
      "   📈 ROC-AUC: 0.5244\n",
      "\n",
      "🔄 Training Naive Bayes...\n",
      "   ✅ Naive Bayes completed in 0.03s\n",
      "   📊 Accuracy: 0.9374\n",
      "   📈 F1-Score - Class 0: 0.0000, Class 1: 0.9677, Weighted: 0.9071\n",
      "   🎯 Precision - Class 0: 0.0000, Class 1: 0.9374\n",
      "   🔍 Recall - Class 0: 0.0000, Class 1: 1.0000\n",
      "   📈 ROC-AUC: 0.6133\n",
      "\n",
      "🔄 Training Linear Discriminant...\n",
      "   ✅ Linear Discriminant completed in 0.05s\n",
      "   📊 Accuracy: 0.9309\n",
      "   📈 F1-Score - Class 0: 0.3013, Class 1: 0.9636, Weighted: 0.9222\n",
      "   🎯 Precision - Class 0: 0.4103, Class 1: 0.9505\n",
      "   🔍 Recall - Class 0: 0.2380, Class 1: 0.9772\n",
      "   📈 ROC-AUC: 0.8379\n",
      "\n",
      "🔄 Training Quadratic Discriminant...\n",
      "   ✅ Quadratic Discriminant completed in 0.04s\n",
      "   📊 Accuracy: 0.9021\n",
      "   📈 F1-Score - Class 0: 0.3585, Class 1: 0.9470, Weighted: 0.9101\n",
      "   🎯 Precision - Class 0: 0.3039, Class 1: 0.9613\n",
      "   🔍 Recall - Class 0: 0.4370, Class 1: 0.9331\n",
      "   📈 ROC-AUC: 0.8293\n",
      "\n",
      "🔄 Training SGD Classifier...\n",
      "   ✅ SGD Classifier completed in 0.32s\n",
      "   📊 Accuracy: 0.9212\n",
      "   📈 F1-Score - Class 0: 0.0411, Class 1: 0.9589, Weighted: 0.9014\n",
      "   🎯 Precision - Class 0: 0.0863, Class 1: 0.9379\n",
      "   🔍 Recall - Class 0: 0.0270, Class 1: 0.9809\n",
      "\n",
      "🔄 Training Extra Trees...\n",
      "   ✅ Extra Trees completed in 5.32s\n",
      "   📊 Accuracy: 0.9371\n",
      "   📈 F1-Score - Class 0: 0.1797, Class 1: 0.9673, Weighted: 0.9180\n",
      "   🎯 Precision - Class 0: 0.4911, Class 1: 0.9435\n",
      "   🔍 Recall - Class 0: 0.1100, Class 1: 0.9924\n",
      "   📈 ROC-AUC: 0.8172\n",
      "\n",
      "🔄 Training XGBoost...\n",
      "   ✅ XGBoost completed in 0.51s\n",
      "   📊 Accuracy: 0.9354\n",
      "   📈 F1-Score - Class 0: 0.2195, Class 1: 0.9663, Weighted: 0.9196\n",
      "   🎯 Precision - Class 0: 0.4517, Class 1: 0.9454\n",
      "   🔍 Recall - Class 0: 0.1450, Class 1: 0.9882\n",
      "   📈 ROC-AUC: 0.8205\n",
      "\n",
      "========================================================================================================================\n",
      "📊 COMPARISON SUMMARY - PER CLASS METRICS\n",
      "========================================================================================================================\n",
      "                 Model  Accuracy  Precision (Class 0)  Precision (Class 1)  Recall (Class 0)  Recall (Class 1)  F1-Score (Class 0)  F1-Score (Class 1)  F1-Score (Weighted) ROC-AUC  Training Time (s)\n",
      "   Linear Discriminant    0.9309               0.4103               0.9505             0.238            0.9772              0.3013              0.9636               0.9222  0.8379             0.0491\n",
      "   Logistic Regression    0.9383               0.5299               0.9443             0.124            0.9927              0.2010              0.9679               0.9199  0.8322             3.8770\n",
      "               XGBoost    0.9354               0.4517               0.9454             0.145            0.9882              0.2195              0.9663               0.9196  0.8205             0.5055\n",
      "     Gradient Boosting    0.9376               0.5082               0.9443             0.124            0.9920              0.1994              0.9676               0.9195  0.8452            12.4959\n",
      "              AdaBoost    0.9381               0.5288               0.9435             0.110            0.9935              0.1821              0.9679               0.9187  0.8352             4.2138\n",
      "         Random Forest    0.9376               0.5068               0.9436             0.111            0.9928              0.1821              0.9675               0.9184   0.826            12.4137\n",
      "           Extra Trees    0.9371               0.4911               0.9435             0.110            0.9924              0.1797              0.9673               0.9180  0.8172             5.3195\n",
      "      Ridge Classifier    0.9384               0.5690               0.9411             0.066            0.9967              0.1183              0.9681               0.9149     N/A             0.0252\n",
      "Quadratic Discriminant    0.9021               0.3039               0.9613             0.437            0.9331              0.3585              0.9470               0.9101  0.8293             0.0386\n",
      "                   SVM    0.9374               0.0000               0.9374             0.000            1.0000              0.0000              0.9677               0.9071  0.5066           247.5108\n",
      "           Naive Bayes    0.9374               0.0000               0.9374             0.000            1.0000              0.0000              0.9677               0.9071  0.6133             0.0292\n",
      "   K-Nearest Neighbors    0.9346               0.0755               0.9374             0.004            0.9967              0.0076              0.9662               0.9061  0.5244             0.7972\n",
      "        SGD Classifier    0.9212               0.0863               0.9379             0.027            0.9809              0.0411              0.9589               0.9014     N/A             0.3167\n",
      "         Decision Tree    0.8937               0.2039               0.9486             0.240            0.9374              0.2205              0.9430               0.8977  0.5887             0.6693\n",
      "\n",
      "🏆 BEST MODEL: Linear Discriminant\n",
      "   Accuracy: 0.9309\n",
      "   F1-Score (Class 0 - No Renewal): 0.3013\n",
      "   F1-Score (Class 1 - Renewal): 0.9636\n",
      "   F1-Score (Weighted): 0.9222\n",
      "   ROC-AUC: 0.8379\n",
      "\n",
      "📋 CLASS INTERPRETATION:\n",
      "   Class 0: No Renewal (Minority class)\n",
      "   Class 1: Renewal (Majority class)\n",
      "   Focus on Class 0 metrics for detecting non-renewals!\n"
     ]
    }
   ],
   "source": [
    "# Example Usage - Run this cell to compare all models\n",
    "\n",
    "# Compare all available classifiers\n",
    "results = compare_models(X_train, X_valid, y_train, y_valid, ALL_CLASSIFIERS)\n",
    "\n",
    "# Or compare specific models only\n",
    "# selected_models = {\n",
    "#     'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "#     'XGBoost': XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'),\n",
    "#     'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "# }\n",
    "# results = compare_models(X_train, X_valid, y_train, y_valid, selected_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical Example: Using the Model Comparison Function\n",
    "\n",
    "# Step 1: Define models to compare\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define your models dictionary\n",
    "models_to_compare = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "print(\"📋 Models defined for comparison:\")\n",
    "for name in models_to_compare.keys():\n",
    "    print(f\"   - {name}\")\n",
    "\n",
    "print(f\"\\n💡 To run the comparison, use:\")\n",
    "print(f\"   results = compare_models(X_train, X_valid, y_train, y_valid, models_to_compare)\")\n",
    "print(f\"\\n💡 For resampling comparison, use:\")\n",
    "print(f\"   resampler = SMOTENC(categorical_features=cat_idx, sampling_strategy='auto', k_neighbors=5, random_state={RANDOM_STATE})\")\n",
    "print(f\"   results = compare_models(X_train, X_valid, y_train, y_valid, models_to_compare, resampler=resampler, cat_cols=cat_cols)\")\n",
    "\n",
    "# Uncomment the lines below to run the actual comparison\n",
    "results = compare_models(X_train, X_valid, y_train, y_valid, models_to_compare)\n",
    "# print(\"\\nResults saved in 'results' variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "📊 SUMMARY FOR MODELS_TO_COMPARE - PER CLASS ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "🎯 FOCUS: CLASS 0 (NO RENEWAL) PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "Ranking by F1-Score (Class 0 - No Renewal Detection):\n",
      "================================================================================\n",
      " 1. Quadratic Discriminant | F1: 0.3585 | Precision: 0.3039 | Recall: 0.4370\n",
      " 2. Linear Discriminant  | F1: 0.3013 | Precision: 0.4103 | Recall: 0.2380\n",
      " 3. Decision Tree        | F1: 0.2205 | Precision: 0.2039 | Recall: 0.2400\n",
      " 4. XGBoost              | F1: 0.2195 | Precision: 0.4517 | Recall: 0.1450\n",
      " 5. Logistic Regression  | F1: 0.2010 | Precision: 0.5299 | Recall: 0.1240\n",
      " 6. Gradient Boosting    | F1: 0.1994 | Precision: 0.5082 | Recall: 0.1240\n",
      " 7. Random Forest        | F1: 0.1821 | Precision: 0.5068 | Recall: 0.1110\n",
      " 8. AdaBoost             | F1: 0.1821 | Precision: 0.5288 | Recall: 0.1100\n",
      " 9. Extra Trees          | F1: 0.1797 | Precision: 0.4911 | Recall: 0.1100\n",
      "10. Ridge Classifier     | F1: 0.1183 | Precision: 0.5690 | Recall: 0.0660\n",
      "11. SGD Classifier       | F1: 0.0411 | Precision: 0.0863 | Recall: 0.0270\n",
      "12. K-Nearest Neighbors  | F1: 0.0076 | Precision: 0.0755 | Recall: 0.0040\n",
      "13. SVM                  | F1: 0.0000 | Precision: 0.0000 | Recall: 0.0000\n",
      "14. Naive Bayes          | F1: 0.0000 | Precision: 0.0000 | Recall: 0.0000\n",
      "\n",
      "🏆 BEST FOR DETECTING NON-RENEWALS (Class 0):\n",
      "   Model: Quadratic Discriminant\n",
      "   F1-Score: 0.3585\n",
      "   Precision: 0.3039\n",
      "   Recall: 0.4370\n",
      "\n",
      "🥇 BEST OVERALL MODEL (Weighted F1):\n",
      "   Model: Linear Discriminant\n",
      "   Weighted F1-Score: 0.9222\n",
      "   Class 0 F1-Score: 0.3013\n",
      "   Class 1 F1-Score: 0.9636\n",
      "\n",
      "📊 PERFORMANCE CATEGORIES:\n",
      "--------------------------------------------------\n",
      "\n",
      "🟢 EXCELLENT at detecting non-renewals (F1 > 0.25):\n",
      "   • Linear Discriminant: F1=0.3013\n",
      "   • Quadratic Discriminant: F1=0.3585\n",
      "\n",
      "🟡 GOOD at detecting non-renewals (0.15 < F1 ≤ 0.25):\n",
      "   • Logistic Regression: F1=0.2010\n",
      "   • XGBoost: F1=0.2195\n",
      "   • Gradient Boosting: F1=0.1994\n",
      "   • AdaBoost: F1=0.1821\n",
      "   • Random Forest: F1=0.1821\n",
      "   • Extra Trees: F1=0.1797\n",
      "   • Decision Tree: F1=0.2205\n",
      "\n",
      "🔴 POOR at detecting non-renewals (F1 ≤ 0.15):\n",
      "   • Ridge Classifier: F1=0.1183\n",
      "   • SVM: F1=0.0000\n",
      "   • Naive Bayes: F1=0.0000\n",
      "   • K-Nearest Neighbors: F1=0.0076\n",
      "   • SGD Classifier: F1=0.0411\n",
      "\n",
      "====================================================================================================\n",
      "✅ SUMMARY COMPLETE - Focus on Class 0 metrics for business success!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary Analysis for models_to_compare Results\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"📊 SUMMARY FOR MODELS_TO_COMPARE - PER CLASS ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Check if results variable exists from the previous cell\n",
    "if 'results' in locals():\n",
    "    print(f\"\\n🎯 FOCUS: CLASS 0 (NO RENEWAL) PERFORMANCE\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Sort by Class 0 F1-Score\n",
    "    class0_focus = results.sort_values('F1-Score (Class 0)', ascending=False)\n",
    "    print(\"Ranking by F1-Score (Class 0 - No Renewal Detection):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, (idx, row) in enumerate(class0_focus.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['Model']:<20} | F1: {row['F1-Score (Class 0)']:.4f} | \"\n",
    "              f\"Precision: {row['Precision (Class 0)']:.4f} | Recall: {row['Recall (Class 0)']:.4f}\")\n",
    "    \n",
    "    # Best performers\n",
    "    best_class0 = class0_focus.iloc[0]\n",
    "    best_overall = results.iloc[0]\n",
    "    \n",
    "    print(f\"\\n🏆 BEST FOR DETECTING NON-RENEWALS (Class 0):\")\n",
    "    print(f\"   Model: {best_class0['Model']}\")\n",
    "    print(f\"   F1-Score: {best_class0['F1-Score (Class 0)']:.4f}\")\n",
    "    print(f\"   Precision: {best_class0['Precision (Class 0)']:.4f}\")\n",
    "    print(f\"   Recall: {best_class0['Recall (Class 0)']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n🥇 BEST OVERALL MODEL (Weighted F1):\")\n",
    "    print(f\"   Model: {best_overall['Model']}\")\n",
    "    print(f\"   Weighted F1-Score: {best_overall['F1-Score (Weighted)']:.4f}\")\n",
    "    print(f\"   Class 0 F1-Score: {best_overall['F1-Score (Class 0)']:.4f}\")\n",
    "    print(f\"   Class 1 F1-Score: {best_overall['F1-Score (Class 1)']:.4f}\")\n",
    "    \n",
    "    # Performance categories\n",
    "    print(f\"\\n📊 PERFORMANCE CATEGORIES:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    high_class0 = results[results['F1-Score (Class 0)'] > 0.25]\n",
    "    print(f\"\\n🟢 EXCELLENT at detecting non-renewals (F1 > 0.25):\")\n",
    "    for _, row in high_class0.iterrows():\n",
    "        print(f\"   • {row['Model']}: F1={row['F1-Score (Class 0)']:.4f}\")\n",
    "    \n",
    "    medium_class0 = results[(results['F1-Score (Class 0)'] > 0.15) & (results['F1-Score (Class 0)'] <= 0.25)]\n",
    "    print(f\"\\n🟡 GOOD at detecting non-renewals (0.15 < F1 ≤ 0.25):\")\n",
    "    for _, row in medium_class0.iterrows():\n",
    "        print(f\"   • {row['Model']}: F1={row['F1-Score (Class 0)']:.4f}\")\n",
    "    \n",
    "    poor_class0 = results[results['F1-Score (Class 0)'] <= 0.15]\n",
    "    print(f\"\\n🔴 POOR at detecting non-renewals (F1 ≤ 0.15):\")\n",
    "    for _, row in poor_class0.iterrows():\n",
    "        print(f\"   • {row['Model']}: F1={row['F1-Score (Class 0)']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 100)\n",
    "    print(\"✅ SUMMARY COMPLETE - Focus on Class 0 metrics for business success!\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No results found. Please run the previous cell first.\")\n",
    "    print(\"💡 Run: results = compare_models(X_train, X_valid, y_train, y_valid, models_to_compare)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
